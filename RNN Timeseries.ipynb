{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Timeseries classification with a Transformer model\n",
        "RNN"
      ],
      "metadata": {
        "id": "XN6QazsNTBk_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1:]\n",
        "    return x, y.astype(int)\n",
        "\n",
        "\n",
        "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
        "\n",
        "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
        "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "idx = np.random.permutation(len(x_train))\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]\n",
        "\n",
        "y_train[y_train == -1] = 0\n",
        "y_test[y_test == -1] = 0"
      ],
      "outputs": [],
      "metadata": {
        "id": "J8om_fVgTBlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model\n"
      ],
      "metadata": {
        "id": "s27EDedYTBlF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,SimpleRNN\n",
        "from keras.utils import to_categorical,plot_model"
      ],
      "outputs": [],
      "metadata": {
        "id": "mvW5FgCoTBlF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "M2bigQw9TBlG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "\n",
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs, outputs)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZDxZ6MWFTBlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and evaluate"
      ],
      "metadata": {
        "id": "ULG6ywkNTBlH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "model.evaluate(x_test, y_test, verbose=1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 500, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 500, 1)      2           ['input_1[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " multi_head_attention (MultiHea  (None, 500, 1)      7169        ['layer_normalization[0][0]',    \n",
            " dAttention)                                                      'layer_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 500, 1)       0           ['multi_head_attention[0][0]']   \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 500, 1)      0           ['dropout[0][0]',                \n",
            " da)                                                              'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add[0][0]']   \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 500, 4)       8           ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 500, 4)       0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 500, 1)       5           ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None, 500, 1)      0           ['conv1d_1[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (MultiH  (None, 500, 1)      7169        ['layer_normalization_2[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, 500, 1)      0           ['dropout_2[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_2[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 500, 4)       0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 500, 1)       5           ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None, 500, 1)      0           ['conv1d_3[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_3[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (MultiH  (None, 500, 1)      7169        ['layer_normalization_4[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (None, 500, 1)      0           ['dropout_4[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_4[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 500, 4)       0           ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 500, 1)       5           ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  (None, 500, 1)      0           ['conv1d_5[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_5[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (MultiH  (None, 500, 1)      7169        ['layer_normalization_6[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  (None, 500, 1)      0           ['dropout_6[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_6[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 500, 4)       0           ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 500, 1)       5           ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  (None, 500, 1)      0           ['conv1d_7[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 500)         0           ['tf.__operators__.add_7[0][0]'] \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          64128       ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 2)            258         ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 93,130\n",
            "Trainable params: 93,130\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/200\n",
            "45/45 [==============================] - 46s 526ms/step - loss: 1.0456 - sparse_categorical_accuracy: 0.5194 - val_loss: 0.7846 - val_sparse_categorical_accuracy: 0.5395\n",
            "Epoch 2/200\n",
            "45/45 [==============================] - 25s 554ms/step - loss: 0.8614 - sparse_categorical_accuracy: 0.5632 - val_loss: 0.7154 - val_sparse_categorical_accuracy: 0.5867\n",
            "Epoch 3/200\n",
            "45/45 [==============================] - 26s 573ms/step - loss: 0.8324 - sparse_categorical_accuracy: 0.5837 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.6186\n",
            "Epoch 4/200\n",
            "45/45 [==============================] - 24s 544ms/step - loss: 0.7632 - sparse_categorical_accuracy: 0.6125 - val_loss: 0.6484 - val_sparse_categorical_accuracy: 0.6366\n",
            "Epoch 5/200\n",
            "45/45 [==============================] - 24s 535ms/step - loss: 0.7295 - sparse_categorical_accuracy: 0.6358 - val_loss: 0.6312 - val_sparse_categorical_accuracy: 0.6491\n",
            "Epoch 6/200\n",
            "45/45 [==============================] - 25s 563ms/step - loss: 0.6931 - sparse_categorical_accuracy: 0.6493 - val_loss: 0.6155 - val_sparse_categorical_accuracy: 0.6630\n",
            "Epoch 7/200\n",
            "45/45 [==============================] - 24s 537ms/step - loss: 0.6662 - sparse_categorical_accuracy: 0.6569 - val_loss: 0.6017 - val_sparse_categorical_accuracy: 0.6685\n",
            "Epoch 8/200\n",
            "45/45 [==============================] - 24s 533ms/step - loss: 0.6579 - sparse_categorical_accuracy: 0.6677 - val_loss: 0.5917 - val_sparse_categorical_accuracy: 0.6838\n",
            "Epoch 9/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.6037 - sparse_categorical_accuracy: 0.6889 - val_loss: 0.5845 - val_sparse_categorical_accuracy: 0.6990\n",
            "Epoch 10/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.5994 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.5751 - val_sparse_categorical_accuracy: 0.7004\n",
            "Epoch 11/200\n",
            "45/45 [==============================] - 25s 557ms/step - loss: 0.5713 - sparse_categorical_accuracy: 0.7063 - val_loss: 0.5673 - val_sparse_categorical_accuracy: 0.7060\n",
            "Epoch 12/200\n",
            "45/45 [==============================] - 24s 542ms/step - loss: 0.5540 - sparse_categorical_accuracy: 0.7122 - val_loss: 0.5591 - val_sparse_categorical_accuracy: 0.7087\n",
            "Epoch 13/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.5530 - sparse_categorical_accuracy: 0.7194 - val_loss: 0.5554 - val_sparse_categorical_accuracy: 0.7157\n",
            "Epoch 14/200\n",
            "45/45 [==============================] - 25s 550ms/step - loss: 0.5462 - sparse_categorical_accuracy: 0.7219 - val_loss: 0.5460 - val_sparse_categorical_accuracy: 0.7143\n",
            "Epoch 15/200\n",
            "45/45 [==============================] - 24s 534ms/step - loss: 0.5265 - sparse_categorical_accuracy: 0.7340 - val_loss: 0.5406 - val_sparse_categorical_accuracy: 0.7226\n",
            "Epoch 16/200\n",
            "45/45 [==============================] - 24s 538ms/step - loss: 0.5320 - sparse_categorical_accuracy: 0.7424 - val_loss: 0.5351 - val_sparse_categorical_accuracy: 0.7282\n",
            "Epoch 17/200\n",
            "45/45 [==============================] - 25s 551ms/step - loss: 0.5101 - sparse_categorical_accuracy: 0.7552 - val_loss: 0.5287 - val_sparse_categorical_accuracy: 0.7337\n",
            "Epoch 18/200\n",
            "45/45 [==============================] - 25s 549ms/step - loss: 0.4917 - sparse_categorical_accuracy: 0.7677 - val_loss: 0.5239 - val_sparse_categorical_accuracy: 0.7337\n",
            "Epoch 19/200\n",
            "45/45 [==============================] - 24s 535ms/step - loss: 0.4803 - sparse_categorical_accuracy: 0.7736 - val_loss: 0.5181 - val_sparse_categorical_accuracy: 0.7406\n",
            "Epoch 20/200\n",
            "45/45 [==============================] - 25s 550ms/step - loss: 0.4638 - sparse_categorical_accuracy: 0.7760 - val_loss: 0.5128 - val_sparse_categorical_accuracy: 0.7462\n",
            "Epoch 21/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.4545 - sparse_categorical_accuracy: 0.7823 - val_loss: 0.5098 - val_sparse_categorical_accuracy: 0.7517\n",
            "Epoch 22/200\n",
            "45/45 [==============================] - 24s 538ms/step - loss: 0.4426 - sparse_categorical_accuracy: 0.7948 - val_loss: 0.5042 - val_sparse_categorical_accuracy: 0.7559\n",
            "Epoch 23/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.4400 - sparse_categorical_accuracy: 0.7937 - val_loss: 0.4989 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 24/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.4263 - sparse_categorical_accuracy: 0.7979 - val_loss: 0.4982 - val_sparse_categorical_accuracy: 0.7573\n",
            "Epoch 25/200\n",
            "45/45 [==============================] - 25s 553ms/step - loss: 0.4308 - sparse_categorical_accuracy: 0.8031 - val_loss: 0.4939 - val_sparse_categorical_accuracy: 0.7587\n",
            "Epoch 26/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.4161 - sparse_categorical_accuracy: 0.8115 - val_loss: 0.4902 - val_sparse_categorical_accuracy: 0.7601\n",
            "Epoch 27/200\n",
            "45/45 [==============================] - 25s 551ms/step - loss: 0.4095 - sparse_categorical_accuracy: 0.8170 - val_loss: 0.4897 - val_sparse_categorical_accuracy: 0.7670\n",
            "Epoch 28/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.3977 - sparse_categorical_accuracy: 0.8181 - val_loss: 0.4841 - val_sparse_categorical_accuracy: 0.7670\n",
            "Epoch 29/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.3981 - sparse_categorical_accuracy: 0.8274 - val_loss: 0.4811 - val_sparse_categorical_accuracy: 0.7739\n",
            "Epoch 30/200\n",
            "45/45 [==============================] - 24s 540ms/step - loss: 0.3852 - sparse_categorical_accuracy: 0.8354 - val_loss: 0.4779 - val_sparse_categorical_accuracy: 0.7781\n",
            "Epoch 31/200\n",
            "45/45 [==============================] - 24s 539ms/step - loss: 0.3800 - sparse_categorical_accuracy: 0.8351 - val_loss: 0.4767 - val_sparse_categorical_accuracy: 0.7822\n",
            "Epoch 32/200\n",
            "45/45 [==============================] - 25s 557ms/step - loss: 0.3770 - sparse_categorical_accuracy: 0.8389 - val_loss: 0.4709 - val_sparse_categorical_accuracy: 0.7809\n",
            "Epoch 33/200\n",
            "45/45 [==============================] - 25s 554ms/step - loss: 0.3738 - sparse_categorical_accuracy: 0.8392 - val_loss: 0.4660 - val_sparse_categorical_accuracy: 0.7753\n",
            "Epoch 34/200\n",
            "45/45 [==============================] - 24s 538ms/step - loss: 0.3596 - sparse_categorical_accuracy: 0.8580 - val_loss: 0.4650 - val_sparse_categorical_accuracy: 0.7822\n",
            "Epoch 35/200\n",
            "45/45 [==============================] - 25s 551ms/step - loss: 0.3624 - sparse_categorical_accuracy: 0.8497 - val_loss: 0.4621 - val_sparse_categorical_accuracy: 0.7767\n",
            "Epoch 36/200\n",
            "45/45 [==============================] - 25s 550ms/step - loss: 0.3534 - sparse_categorical_accuracy: 0.8521 - val_loss: 0.4604 - val_sparse_categorical_accuracy: 0.7850\n",
            "Epoch 37/200\n",
            "45/45 [==============================] - 24s 536ms/step - loss: 0.3514 - sparse_categorical_accuracy: 0.8531 - val_loss: 0.4588 - val_sparse_categorical_accuracy: 0.7864\n",
            "Epoch 38/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.3393 - sparse_categorical_accuracy: 0.8604 - val_loss: 0.4564 - val_sparse_categorical_accuracy: 0.7892\n",
            "Epoch 39/200\n",
            "45/45 [==============================] - 24s 541ms/step - loss: 0.3404 - sparse_categorical_accuracy: 0.8611 - val_loss: 0.4502 - val_sparse_categorical_accuracy: 0.7961\n",
            "Epoch 40/200\n",
            "45/45 [==============================] - 25s 554ms/step - loss: 0.3309 - sparse_categorical_accuracy: 0.8646 - val_loss: 0.4470 - val_sparse_categorical_accuracy: 0.8003\n",
            "Epoch 41/200\n",
            "45/45 [==============================] - 24s 537ms/step - loss: 0.3388 - sparse_categorical_accuracy: 0.8587 - val_loss: 0.4475 - val_sparse_categorical_accuracy: 0.7961\n",
            "Epoch 42/200\n",
            "45/45 [==============================] - 25s 553ms/step - loss: 0.3275 - sparse_categorical_accuracy: 0.8715 - val_loss: 0.4449 - val_sparse_categorical_accuracy: 0.7989\n",
            "Epoch 43/200\n",
            "45/45 [==============================] - 25s 551ms/step - loss: 0.3269 - sparse_categorical_accuracy: 0.8649 - val_loss: 0.4423 - val_sparse_categorical_accuracy: 0.7947\n",
            "Epoch 44/200\n",
            "45/45 [==============================] - 25s 552ms/step - loss: 0.3199 - sparse_categorical_accuracy: 0.8705 - val_loss: 0.4367 - val_sparse_categorical_accuracy: 0.8003\n",
            "Epoch 45/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.3200 - sparse_categorical_accuracy: 0.8726 - val_loss: 0.4358 - val_sparse_categorical_accuracy: 0.7947\n",
            "Epoch 46/200\n",
            "45/45 [==============================] - 25s 557ms/step - loss: 0.3092 - sparse_categorical_accuracy: 0.8715 - val_loss: 0.4344 - val_sparse_categorical_accuracy: 0.7989\n",
            "Epoch 47/200\n",
            "45/45 [==============================] - 24s 538ms/step - loss: 0.3066 - sparse_categorical_accuracy: 0.8833 - val_loss: 0.4318 - val_sparse_categorical_accuracy: 0.7961\n",
            "Epoch 48/200\n",
            "45/45 [==============================] - 25s 551ms/step - loss: 0.3091 - sparse_categorical_accuracy: 0.8760 - val_loss: 0.4288 - val_sparse_categorical_accuracy: 0.8044\n",
            "Epoch 49/200\n",
            "45/45 [==============================] - 25s 553ms/step - loss: 0.3060 - sparse_categorical_accuracy: 0.8823 - val_loss: 0.4289 - val_sparse_categorical_accuracy: 0.8031\n",
            "Epoch 50/200\n",
            "45/45 [==============================] - 24s 534ms/step - loss: 0.2950 - sparse_categorical_accuracy: 0.8847 - val_loss: 0.4246 - val_sparse_categorical_accuracy: 0.8100\n",
            "Epoch 51/200\n",
            "45/45 [==============================] - 24s 535ms/step - loss: 0.2926 - sparse_categorical_accuracy: 0.8903 - val_loss: 0.4235 - val_sparse_categorical_accuracy: 0.8128\n",
            "Epoch 52/200\n",
            "45/45 [==============================] - 25s 549ms/step - loss: 0.2875 - sparse_categorical_accuracy: 0.8944 - val_loss: 0.4197 - val_sparse_categorical_accuracy: 0.8100\n",
            "Epoch 53/200\n",
            "45/45 [==============================] - 25s 554ms/step - loss: 0.2783 - sparse_categorical_accuracy: 0.8920 - val_loss: 0.4175 - val_sparse_categorical_accuracy: 0.8155\n",
            "Epoch 54/200\n",
            "45/45 [==============================] - 25s 551ms/step - loss: 0.2900 - sparse_categorical_accuracy: 0.8865 - val_loss: 0.4168 - val_sparse_categorical_accuracy: 0.8100\n",
            "Epoch 55/200\n",
            "45/45 [==============================] - 25s 554ms/step - loss: 0.2814 - sparse_categorical_accuracy: 0.8955 - val_loss: 0.4193 - val_sparse_categorical_accuracy: 0.8141\n",
            "Epoch 56/200\n",
            "45/45 [==============================] - 24s 539ms/step - loss: 0.2741 - sparse_categorical_accuracy: 0.9000 - val_loss: 0.4167 - val_sparse_categorical_accuracy: 0.8169\n",
            "Epoch 57/200\n",
            "45/45 [==============================] - 25s 554ms/step - loss: 0.2756 - sparse_categorical_accuracy: 0.8965 - val_loss: 0.4131 - val_sparse_categorical_accuracy: 0.8128\n",
            "Epoch 58/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.2695 - sparse_categorical_accuracy: 0.9017 - val_loss: 0.4121 - val_sparse_categorical_accuracy: 0.8211\n",
            "Epoch 59/200\n",
            "45/45 [==============================] - 25s 552ms/step - loss: 0.2654 - sparse_categorical_accuracy: 0.9031 - val_loss: 0.4109 - val_sparse_categorical_accuracy: 0.8169\n",
            "Epoch 60/200\n",
            "45/45 [==============================] - 25s 553ms/step - loss: 0.2591 - sparse_categorical_accuracy: 0.9024 - val_loss: 0.4109 - val_sparse_categorical_accuracy: 0.8155\n",
            "Epoch 61/200\n",
            "45/45 [==============================] - 25s 553ms/step - loss: 0.2630 - sparse_categorical_accuracy: 0.9028 - val_loss: 0.4087 - val_sparse_categorical_accuracy: 0.8183\n",
            "Epoch 62/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.2463 - sparse_categorical_accuracy: 0.9038 - val_loss: 0.4073 - val_sparse_categorical_accuracy: 0.8211\n",
            "Epoch 63/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.2544 - sparse_categorical_accuracy: 0.9083 - val_loss: 0.4018 - val_sparse_categorical_accuracy: 0.8225\n",
            "Epoch 64/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.2532 - sparse_categorical_accuracy: 0.9014 - val_loss: 0.4023 - val_sparse_categorical_accuracy: 0.8211\n",
            "Epoch 65/200\n",
            "45/45 [==============================] - 24s 540ms/step - loss: 0.2534 - sparse_categorical_accuracy: 0.9056 - val_loss: 0.4037 - val_sparse_categorical_accuracy: 0.8266\n",
            "Epoch 66/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.2489 - sparse_categorical_accuracy: 0.9052 - val_loss: 0.3995 - val_sparse_categorical_accuracy: 0.8280\n",
            "Epoch 67/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.2425 - sparse_categorical_accuracy: 0.9177 - val_loss: 0.3992 - val_sparse_categorical_accuracy: 0.8197\n",
            "Epoch 68/200\n",
            "45/45 [==============================] - 24s 535ms/step - loss: 0.2442 - sparse_categorical_accuracy: 0.9111 - val_loss: 0.3972 - val_sparse_categorical_accuracy: 0.8266\n",
            "Epoch 69/200\n",
            "45/45 [==============================] - 25s 553ms/step - loss: 0.2272 - sparse_categorical_accuracy: 0.9208 - val_loss: 0.3941 - val_sparse_categorical_accuracy: 0.8266\n",
            "Epoch 70/200\n",
            "45/45 [==============================] - 25s 554ms/step - loss: 0.2319 - sparse_categorical_accuracy: 0.9156 - val_loss: 0.3967 - val_sparse_categorical_accuracy: 0.8280\n",
            "Epoch 71/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.2379 - sparse_categorical_accuracy: 0.9125 - val_loss: 0.3917 - val_sparse_categorical_accuracy: 0.8280\n",
            "Epoch 72/200\n",
            "45/45 [==============================] - 24s 537ms/step - loss: 0.2276 - sparse_categorical_accuracy: 0.9222 - val_loss: 0.3921 - val_sparse_categorical_accuracy: 0.8266\n",
            "Epoch 73/200\n",
            "45/45 [==============================] - 24s 541ms/step - loss: 0.2275 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.3929 - val_sparse_categorical_accuracy: 0.8280\n",
            "Epoch 74/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.2346 - sparse_categorical_accuracy: 0.9118 - val_loss: 0.3962 - val_sparse_categorical_accuracy: 0.8266\n",
            "Epoch 75/200\n",
            "45/45 [==============================] - 24s 539ms/step - loss: 0.2235 - sparse_categorical_accuracy: 0.9187 - val_loss: 0.3893 - val_sparse_categorical_accuracy: 0.8280\n",
            "Epoch 76/200\n",
            "45/45 [==============================] - 24s 539ms/step - loss: 0.2262 - sparse_categorical_accuracy: 0.9212 - val_loss: 0.3865 - val_sparse_categorical_accuracy: 0.8322\n",
            "Epoch 77/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.2161 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.3890 - val_sparse_categorical_accuracy: 0.8294\n",
            "Epoch 78/200\n",
            "45/45 [==============================] - 25s 554ms/step - loss: 0.2130 - sparse_categorical_accuracy: 0.9271 - val_loss: 0.3889 - val_sparse_categorical_accuracy: 0.8322\n",
            "Epoch 79/200\n",
            "45/45 [==============================] - 25s 552ms/step - loss: 0.2104 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.3872 - val_sparse_categorical_accuracy: 0.8294\n",
            "Epoch 80/200\n",
            "45/45 [==============================] - 24s 539ms/step - loss: 0.2017 - sparse_categorical_accuracy: 0.9351 - val_loss: 0.3875 - val_sparse_categorical_accuracy: 0.8350\n",
            "Epoch 81/200\n",
            "45/45 [==============================] - 24s 539ms/step - loss: 0.2078 - sparse_categorical_accuracy: 0.9267 - val_loss: 0.3859 - val_sparse_categorical_accuracy: 0.8308\n",
            "Epoch 82/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.2021 - sparse_categorical_accuracy: 0.9302 - val_loss: 0.3911 - val_sparse_categorical_accuracy: 0.8308\n",
            "Epoch 83/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.2030 - sparse_categorical_accuracy: 0.9274 - val_loss: 0.3860 - val_sparse_categorical_accuracy: 0.8336\n",
            "Epoch 84/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.2042 - sparse_categorical_accuracy: 0.9312 - val_loss: 0.3850 - val_sparse_categorical_accuracy: 0.8350\n",
            "Epoch 85/200\n",
            "45/45 [==============================] - 25s 558ms/step - loss: 0.2071 - sparse_categorical_accuracy: 0.9278 - val_loss: 0.3858 - val_sparse_categorical_accuracy: 0.8350\n",
            "Epoch 86/200\n",
            "45/45 [==============================] - 25s 553ms/step - loss: 0.2053 - sparse_categorical_accuracy: 0.9278 - val_loss: 0.3838 - val_sparse_categorical_accuracy: 0.8336\n",
            "Epoch 87/200\n",
            "45/45 [==============================] - 24s 544ms/step - loss: 0.1932 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.3818 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 88/200\n",
            "45/45 [==============================] - 25s 557ms/step - loss: 0.1976 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.3826 - val_sparse_categorical_accuracy: 0.8322\n",
            "Epoch 89/200\n",
            "45/45 [==============================] - 25s 552ms/step - loss: 0.1976 - sparse_categorical_accuracy: 0.9340 - val_loss: 0.3819 - val_sparse_categorical_accuracy: 0.8363\n",
            "Epoch 90/200\n",
            "45/45 [==============================] - 25s 554ms/step - loss: 0.1922 - sparse_categorical_accuracy: 0.9392 - val_loss: 0.3803 - val_sparse_categorical_accuracy: 0.8336\n",
            "Epoch 91/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.1951 - sparse_categorical_accuracy: 0.9344 - val_loss: 0.3787 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 92/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.1944 - sparse_categorical_accuracy: 0.9281 - val_loss: 0.3803 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 93/200\n",
            "45/45 [==============================] - 25s 553ms/step - loss: 0.1851 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.3807 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 94/200\n",
            "45/45 [==============================] - 25s 553ms/step - loss: 0.1856 - sparse_categorical_accuracy: 0.9351 - val_loss: 0.3787 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 95/200\n",
            "45/45 [==============================] - 24s 536ms/step - loss: 0.1865 - sparse_categorical_accuracy: 0.9392 - val_loss: 0.3807 - val_sparse_categorical_accuracy: 0.8336\n",
            "Epoch 96/200\n",
            "45/45 [==============================] - 25s 557ms/step - loss: 0.1886 - sparse_categorical_accuracy: 0.9267 - val_loss: 0.3776 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 97/200\n",
            "45/45 [==============================] - 24s 540ms/step - loss: 0.1839 - sparse_categorical_accuracy: 0.9337 - val_loss: 0.3780 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 98/200\n",
            "45/45 [==============================] - 25s 558ms/step - loss: 0.1815 - sparse_categorical_accuracy: 0.9396 - val_loss: 0.3767 - val_sparse_categorical_accuracy: 0.8433\n",
            "Epoch 99/200\n",
            "45/45 [==============================] - 25s 557ms/step - loss: 0.1854 - sparse_categorical_accuracy: 0.9340 - val_loss: 0.3782 - val_sparse_categorical_accuracy: 0.8350\n",
            "Epoch 100/200\n",
            "45/45 [==============================] - 24s 540ms/step - loss: 0.1713 - sparse_categorical_accuracy: 0.9392 - val_loss: 0.3767 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 101/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.1723 - sparse_categorical_accuracy: 0.9365 - val_loss: 0.3740 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 102/200\n",
            "45/45 [==============================] - 24s 544ms/step - loss: 0.1740 - sparse_categorical_accuracy: 0.9347 - val_loss: 0.3735 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 103/200\n",
            "45/45 [==============================] - 25s 557ms/step - loss: 0.1720 - sparse_categorical_accuracy: 0.9444 - val_loss: 0.3759 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 104/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.1667 - sparse_categorical_accuracy: 0.9490 - val_loss: 0.3763 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 105/200\n",
            "45/45 [==============================] - 24s 538ms/step - loss: 0.1695 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3732 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 106/200\n",
            "45/45 [==============================] - 24s 537ms/step - loss: 0.1659 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3722 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 107/200\n",
            "45/45 [==============================] - 25s 553ms/step - loss: 0.1617 - sparse_categorical_accuracy: 0.9514 - val_loss: 0.3709 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 108/200\n",
            "45/45 [==============================] - 25s 553ms/step - loss: 0.1615 - sparse_categorical_accuracy: 0.9483 - val_loss: 0.3756 - val_sparse_categorical_accuracy: 0.8433\n",
            "Epoch 109/200\n",
            "45/45 [==============================] - 24s 542ms/step - loss: 0.1586 - sparse_categorical_accuracy: 0.9483 - val_loss: 0.3784 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 110/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.1582 - sparse_categorical_accuracy: 0.9472 - val_loss: 0.3748 - val_sparse_categorical_accuracy: 0.8433\n",
            "Epoch 111/200\n",
            "45/45 [==============================] - 25s 557ms/step - loss: 0.1626 - sparse_categorical_accuracy: 0.9420 - val_loss: 0.3746 - val_sparse_categorical_accuracy: 0.8447\n",
            "Epoch 112/200\n",
            "45/45 [==============================] - 25s 555ms/step - loss: 0.1620 - sparse_categorical_accuracy: 0.9392 - val_loss: 0.3773 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 113/200\n",
            "45/45 [==============================] - 25s 554ms/step - loss: 0.1617 - sparse_categorical_accuracy: 0.9413 - val_loss: 0.3732 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 114/200\n",
            "45/45 [==============================] - 25s 560ms/step - loss: 0.1566 - sparse_categorical_accuracy: 0.9458 - val_loss: 0.3769 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 115/200\n",
            "45/45 [==============================] - 25s 559ms/step - loss: 0.1492 - sparse_categorical_accuracy: 0.9486 - val_loss: 0.3782 - val_sparse_categorical_accuracy: 0.8474\n",
            "Epoch 116/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.1667 - sparse_categorical_accuracy: 0.9431 - val_loss: 0.3721 - val_sparse_categorical_accuracy: 0.8433\n",
            "Epoch 117/200\n",
            "45/45 [==============================] - 24s 540ms/step - loss: 0.1498 - sparse_categorical_accuracy: 0.9521 - val_loss: 0.3701 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 118/200\n",
            "45/45 [==============================] - 24s 540ms/step - loss: 0.1561 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.3731 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 119/200\n",
            "45/45 [==============================] - 24s 543ms/step - loss: 0.1523 - sparse_categorical_accuracy: 0.9469 - val_loss: 0.3736 - val_sparse_categorical_accuracy: 0.8433\n",
            "Epoch 120/200\n",
            "45/45 [==============================] - 25s 558ms/step - loss: 0.1493 - sparse_categorical_accuracy: 0.9510 - val_loss: 0.3739 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 121/200\n",
            "45/45 [==============================] - 24s 542ms/step - loss: 0.1407 - sparse_categorical_accuracy: 0.9538 - val_loss: 0.3722 - val_sparse_categorical_accuracy: 0.8433\n",
            "Epoch 122/200\n",
            "45/45 [==============================] - 25s 554ms/step - loss: 0.1501 - sparse_categorical_accuracy: 0.9521 - val_loss: 0.3747 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 123/200\n",
            "45/45 [==============================] - 25s 557ms/step - loss: 0.1396 - sparse_categorical_accuracy: 0.9590 - val_loss: 0.3725 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 124/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.1474 - sparse_categorical_accuracy: 0.9535 - val_loss: 0.3695 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 125/200\n",
            "45/45 [==============================] - 25s 559ms/step - loss: 0.1423 - sparse_categorical_accuracy: 0.9549 - val_loss: 0.3687 - val_sparse_categorical_accuracy: 0.8488\n",
            "Epoch 126/200\n",
            "45/45 [==============================] - 24s 541ms/step - loss: 0.1456 - sparse_categorical_accuracy: 0.9538 - val_loss: 0.3765 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 127/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.1427 - sparse_categorical_accuracy: 0.9538 - val_loss: 0.3730 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 128/200\n",
            "45/45 [==============================] - 25s 557ms/step - loss: 0.1426 - sparse_categorical_accuracy: 0.9528 - val_loss: 0.3760 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 129/200\n",
            "45/45 [==============================] - 24s 538ms/step - loss: 0.1319 - sparse_categorical_accuracy: 0.9601 - val_loss: 0.3741 - val_sparse_categorical_accuracy: 0.8363\n",
            "Epoch 130/200\n",
            "45/45 [==============================] - 25s 554ms/step - loss: 0.1476 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.3710 - val_sparse_categorical_accuracy: 0.8474\n",
            "Epoch 131/200\n",
            "45/45 [==============================] - 24s 542ms/step - loss: 0.1362 - sparse_categorical_accuracy: 0.9559 - val_loss: 0.3740 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 132/200\n",
            "45/45 [==============================] - 25s 556ms/step - loss: 0.1411 - sparse_categorical_accuracy: 0.9524 - val_loss: 0.3764 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 133/200\n",
            "45/45 [==============================] - 25s 554ms/step - loss: 0.1412 - sparse_categorical_accuracy: 0.9597 - val_loss: 0.3764 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 134/200\n",
            "45/45 [==============================] - 24s 539ms/step - loss: 0.1361 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.3782 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 135/200\n",
            "45/45 [==============================] - 24s 539ms/step - loss: 0.1335 - sparse_categorical_accuracy: 0.9566 - val_loss: 0.3794 - val_sparse_categorical_accuracy: 0.8350\n",
            "42/42 [==============================] - 4s 82ms/step - loss: 0.3371 - sparse_categorical_accuracy: 0.8553\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3371064364910126, 0.8553030490875244]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "metadata": {
        "id": "_0GgUkMiTBlH",
        "outputId": "8692460d-ec8c-4e3c-b18f-35f48cec8e53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions\n",
        "\n",
        "In about 110-120 epochs (25s each on Colab), the model reaches a training\n",
        "accuracy of ~0.95, validation accuracy of ~84 and a testing\n",
        "accuracy of ~85, without hyperparameter tuning. And that is for a model\n",
        "with less than 100k parameters. Of course, parameter count and accuracy could be\n",
        "improved by a hyperparameter search and a more sophisticated learning rate\n",
        "schedule, or a different optimizer.\n",
        "\n",
        "You can use the trained model hosted on [Hugging Face Hub](https://huggingface.co/keras-io/timeseries_transformer_classification) and try the demo on [Hugging Face Spaces](https://huggingface.co/spaces/keras-io/timeseries_transformer_classification)."
      ],
      "metadata": {
        "id": "jgRa4NWtTBlH"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "timeseries_transformer_classification",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}